\begin{thebibliography}{10}

\bibitem{function_approximation}
Leemon Baird.
\newblock Reinforcement learning with function approximation.
\newblock {\em Proceedings of the 12th International Conference on Machine
  Learning (ICML 1995)}, pages 30--37, 1995.

\bibitem{states_vs_rewards}
Jan Glascher, Peter Dayan, and John~P. O'Doherty.
\newblock States versus rewards: Dissociable neural prediction error signals
  underlying model-based and model-free reinforcement learning.
\newblock (4), 2021.

\bibitem{discretization_tech}
Rohan Gupta.
\newblock An introduction to discretization techniques for data scientists,
  2019.

\bibitem{soft_update}
Timothy~P. Lillicrap, Jonathan~J. Hunt, Alexander Pritzel, Nicolas Heess, Tom
  Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning, 2019.

\bibitem{neural_network}
Longxin Lin.
\newblock Reinforcement learning for robots using neural networks.
\newblock 1992.

\bibitem{convergence}
Hamid Maei, Csaba Szepesv\'{a}ri, Shalabh Bhatnagar, Doina Precup, David
  Silver, and Richard~S Sutton.
\newblock Convergent temporal-difference learning with arbitrary smooth
  function approximation.
\newblock In Y.~Bengio, D.~Schuurmans, J.~Lafferty, C.~Williams, and
  A.~Culotta, editors, {\em Advances in Neural Information Processing Systems},
  volume~22. Curran Associates, Inc., 2009.

\bibitem{learning_control}
Hamid~Reza Maei, Csaba Szepesv{\'a}ri, Shalabh Bhatnagar, and Richard~S.
  Sutton.
\newblock Toward off-policy learning control with function approximation.
\newblock In Johannes F{\"u}rnkranz and Thorsten Joachims, editors, {\em
  Proceedings of the Twenty-seventh International Conference on Machine
  Learning (ICML 2010)}, pages 719--726. Omnipress, 2010.

\bibitem{DBLP:journals/corr/MnihKSGAWR13}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin~A. Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em CoRR}, abs/1312.5602, 2013.

\bibitem{feedback_control}
Hafner R and Riedmiller M.
\newblock Reinforcement learning in feedback control.
\newblock 2011.

\bibitem{hubert}
George Seif.
\newblock Understanding the 3 most common loss functions for machine learning
  regression, 2019.

\bibitem{ddpg}
David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and
  Martin Riedmiller.
\newblock Deterministic policy gradient algorithms.
\newblock In Eric~P. Xing and Tony Jebara, editors, {\em Proceedings of the
  31st International Conference on Machine Learning}, volume~32 of {\em
  Proceedings of Machine Learning Research}, pages 387--395, Bejing, China,
  22--24 Jun 2014. PMLR.

\bibitem{sutton}
Richard~S. Sutton and Andrew~G. Barto.
\newblock {\em Reinforcement Learning: An Introduction}.
\newblock The MIT Press, second edition, 2018.

\bibitem{temporal_diff}
J.N. Tsitsiklis and B.~Van~Roy.
\newblock An analysis of temporal-difference learning with function
  approximation.
\newblock {\em IEEE Transactions on Automatic Control}, 42(5):674--690, 1997.

\bibitem{human_control}
Mnih V., Kavukcuoglu K., and Silver D.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(529-533), 2015.

\bibitem{qlearning}
Watkings, Dayan P., and C.J.C.H.
\newblock Q-learning.
\newblock {\em Mach Learn}, 8(279-292), 1992.

\bibitem{noise}
Pawel Wawrzynski.
\newblock Control policy with autocorrelated noise in reinforcement learning
  for robotics.
\newblock {\em International Journal of Machine Learning and Computing},
  5:91--95, 04 2015.

\bibitem{replay}
Pawel Wawrzynski and Ajay~Kumar Tanwani.
\newblock Autonomous reinforcement learning with experience replay.
\newblock {\em PubMed}, 41(156-67), 2012.

\end{thebibliography}
